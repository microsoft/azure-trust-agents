
# Azure Trust and Compliance Multi-Agents Hack ğŸ¤–

Welcome to the Automated Compliance Agents Hackathon! ğŸ¦ Today, you'll dive into the world of intelligent agent systems powered by Azure AI to revolutionize regulatory compliance in financial services. Get ready for a hands-on, high-impact day of learning and innovation!

## Introduction 

Get ready to transform compliance with AI! In this hackathon, you'll build intelligent agents that parse regulations, monitor transactions, and generate transparent audit trailsâ€”just like real compliance teams. From reading new laws to flagging suspicious activity, your agents will collaborate to automate complex regulatory workflows in minutes, not months. By the end, you'll have created a powerful multi-agent system that redefines how financial institutions stay compliant and build trust. 

## Architecture ğŸ—ï¸


## Requirements ğŸ“‹
To successfully complete this hackathon, you will need the following:

- GitHub account to access the repository and run GitHub Codespaces and Github Copilot. 
- Be familiar with Python programming, including handling JSON data and making API calls.â€‹ 
- Be familiar with Generative AI Solutions and Azure  Services. 
- An active Azure subscription, with Owner rights. 
- Ability to provision resources in **Sweden Central** or [another supported region](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models?tabs=global-standard%2Cstandard-chat-completions#global-standard-model-availability). 

## Challenges ğŸš©

- Challenge 00: **[Get Set](challenge-0/readme.md)** : Resource Deployment, Github Codespaces + .env Variables + Data ingestion
- Challenge 01: **[Create your Agents](challenge-1/readme.md)** : Azure AI Agent with Semantic Kernel
- Challenge 02: **[Extend your Agents](challenge-2/readme.md)** : APIM + MCP Server
- Challenge 03: **[Use your Memory | Cosmos DB ](challenge-3/readme.md)** : Cosmos
- Challenge 04: **[Gain peace of mind](challenge-4/readme.md)** : | Monitoring APIs, Responsible AI (Evaluation with GH Actions, Observability, Safety)
